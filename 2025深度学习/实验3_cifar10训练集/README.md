# 实验三：基本卷积网络的搭建及训练

## 实验目的
通过实践辅助理解卷积神经网络模型，掌握搭建卷积神经网络的模型搭建方法和训练方法，掌握卷积神经网络参数的调整和模型评估的方法。

## 实验内容
在CIFAR-10数据集上自行设计并搭建卷积神经网络模型，完成模型训练、参数调整和性能评估。

## 代码文件说明
本项目包含以下文件：
- `cifar10_cnn.py`: 完整的Python脚本，包含所有实验步骤
- `CIFAR10_CNN实验.ipynb`: Jupyter Notebook格式的实验文件（与Python脚本内容相同）

## 实验步骤

### 1. 完成CIFAR-10数据集的数据读取，并完成数据集的初步探索
- 定义数据转换（数据增强和标准化）
- 加载训练集和测试集
- 可视化一些训练样本并显示其标签

### 2. 定义模型
- 设计一个包含4个卷积层和2个全连接层的CNN模型
- 使用批归一化和Dropout等技术提高模型性能

### 3. 定义损失函数
- 使用交叉熵损失函数（CrossEntropyLoss）

### 4. 定义优化方法
- 使用Adam优化器，学习率设置为0.001

### 5. 模型训练
- 实现训练函数，记录训练和测试的损失及准确率
- 在每个Epoch结束后评估模型在测试集上的性能
- 训练10个Epoch

### 6. 模型评估
- 在测试集上计算混淆矩阵
- 计算并可视化每个类别的准确率
- 输出总体测试准确率

### 7. 可视化与分析
- 绘制训练和测试的损失曲线
- 绘制训练和测试的准确率曲线
- 可视化第一层卷积核
- 进行结果分析和总结

## 运行方式

### 使用Python脚本运行
```bash
python cifar10_cnn.py
```

### 使用Jupyter Notebook运行
1. 打开Jupyter Notebook
```bash
jupyter notebook
```
2. 打开`CIFAR10_CNN实验.ipynb`文件
3. 按顺序执行所有代码单元格

## 实验结果分析

1. **模型结构**：我们构建了一个包含4个卷积层和2个全连接层的CNN模型，每个卷积层后接批归一化和ReLU激活函数，使用了最大池化层减小特征图尺寸，并在全连接层中加入了Dropout以减轻过拟合。

2. **训练过程**：我们对模型进行了10轮训练，可以从损失和准确率曲线中观察到模型在训练过程中的收敛情况。

3. **模型性能**：通过混淆矩阵和每个类别的准确率分析，我们可以了解模型在不同类别上的表现。

4. **卷积核可视化**：通过第一层卷积核的可视化，我们可以直观地看到模型学习到的低级特征。

5. **改进方向**：
   - 增加训练轮次，观察模型是否能够进一步提高性能
   - 尝试不同的网络结构，如ResNet或DenseNet
   - 使用更多的数据增强技术
   - 调整学习率和批次大小等超参数
   - 使用学习率调度器动态调整学习率 